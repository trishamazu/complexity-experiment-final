{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, linregress\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('/home/wallacelab/complexity-final/')\n",
    "\n",
    "import optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_simulations = 10  # Number of simulations to run\n",
    "task_name = \"complexity_prediction\"\n",
    "predictor_columns = [\"Irregularity\", \"Disorganized\", \"Asymmetry\", \"Chaotic\", \"Randomness\", \n",
    "                     \"Variability\", \"Multicolored\", \"Heterogeneity\", \"Grainy\", \"Isotropy\", \n",
    "                     \"Cluttered\", \"Ambiguity\", \"Intricate\"]\n",
    "all_weights = []\n",
    "spearman_rhos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation multiple times\n",
    "for _ in range(num_simulations):\n",
    "    # Load your data \n",
    "    df1 = pd.read_csv('path')\n",
    "    df2 = pd.read_csv('path')\n",
    "    \n",
    "    # Run the bayesian optimization function (make sure it's defined in this notebook or imported)\n",
    "    best_weights, best_rho = optimization.bayesian_optimization_fit(df1, df2, predictor_columns, task_name=task_name, cross_validate=False)\n",
    "    all_weights.append(best_weights)\n",
    "    spearman_rhos.append(best_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert weights results to a DataFrame\n",
    "weights_df = pd.DataFrame(all_weights, columns=predictor_columns)\n",
    "\n",
    "# Assuming `weights_df` is already calculated from the simulation results\n",
    "mean_weights = weights_df.mean()\n",
    "se_weights = weights_df.sem()\n",
    "\n",
    "# Combine mean and standard error into a new DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'Predictor': predictor_columns,\n",
    "    'Mean Weight': mean_weights,\n",
    "    'SE Weight': se_weights\n",
    "})\n",
    "\n",
    "# Create a unique directory or file name based on a timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f'./optimization_results_{timestamp}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the summary DataFrame as a CSV in the new directory\n",
    "summary_csv_path = os.path.join(output_dir, 'weights_summary.csv')\n",
    "summary_df.to_csv(summary_csv_path, index=False)\n",
    "\n",
    "print(f\"Summary of weights saved in: {summary_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart with error bars for each characteristic\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(mean_weights.index, mean_weights, yerr=se_weights, capsize=5)\n",
    "plt.xlabel(\"Characteristic\")\n",
    "plt.ylabel(\"Mean Weight\")\n",
    "plt.title(\"Distribution of Weights Across Dimensions\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best (highest) Spearman rho and corresponding weights\n",
    "best_rho_index = np.argmax(spearman_rhos)\n",
    "best_rho = spearman_rhos[best_rho_index]\n",
    "best_weights = all_weights[best_rho_index]\n",
    "\n",
    "# Calculate predictions for each image using the best weights\n",
    "# Assuming `df2` contains predictor columns and `df1` contains the actual values\n",
    "df1 = pd.read_csv('path')\n",
    "df2 = pd.read_csv('path')\n",
    "\n",
    "# Ensure that df1 and df2 are aligned by merging on 'image' column if necessary\n",
    "if 'image' in df1.columns and 'image' in df2.columns:\n",
    "    combined_df = pd.merge(df1, df2, on='image')\n",
    "    y_true = combined_df['Normalized Average'].values\n",
    "    X = combined_df[predictor_columns].values\n",
    "else:\n",
    "    y_true = df1['Normalized Average'].values\n",
    "    X = df2[predictor_columns].values\n",
    "\n",
    "# Get predicted values by multiplying X by best weights\n",
    "y_pred = X @ best_weights\n",
    "\n",
    "# Calculate the line of best fit for predicted vs. actual\n",
    "slope, intercept, _, _, _ = linregress(y_pred, y_true)  # Predicted (x) vs. Actual (y)\n",
    "line_x = np.linspace(y_pred.min(), y_pred.max(), 100)  # Restrict line_x to the range of predicted values\n",
    "line_y = slope * line_x + intercept  # Compute corresponding y values using the regression equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter plot and line of best fit\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, y_true, label=\"Predicted vs. Actual\")  # Predicted on x, Actual on y\n",
    "plt.plot(line_x, line_y, color=\"red\", label=\"Line of Best Fit\")  # Best-fit line for predicted vs. actual\n",
    "plt.xlabel(\"CLIP-CBA Complexity Score (Predicted)\")\n",
    "plt.ylabel(\"Normalized Participant Complexity Rating (Actual)\")\n",
    "plt.title(f\"CLIP-CBA Optimization vs. Participant Ratings: Spearman Rho = {best_rho:.4f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
