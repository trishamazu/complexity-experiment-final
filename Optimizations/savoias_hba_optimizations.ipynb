{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, linregress\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('/home/wallacelab/complexity-final/Optimizations')\n",
    "\n",
    "import optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_simulations = 1  # Number of simulations to run\n",
    "task_name = \"complexity_prediction\"\n",
    "\n",
    "# Dynamically generate predictor column names '0' through '48'\n",
    "predictor_columns = [str(i) for i in range(49)]\n",
    "\n",
    "all_weights = []\n",
    "spearman_rhos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: ./optimization_results_20241127_123758\n",
      "Starting optimization without cross-validation...\n",
      "Calculating initial Spearman correlations for each predictor...\n",
      "Predictor 0: Initial Spearman rho = -0.05218738434664632\n",
      "Predictor 1: Initial Spearman rho = -0.010680829955260325\n",
      "Predictor 2: Initial Spearman rho = -0.08557266713418006\n",
      "Predictor 3: Initial Spearman rho = -0.010891625939066207\n",
      "Predictor 4: Initial Spearman rho = -0.018621312121044183\n",
      "Predictor 5: Initial Spearman rho = 0.04452596305622114\n",
      "Predictor 6: Initial Spearman rho = 0.013043095268444395\n",
      "Predictor 7: Initial Spearman rho = -0.03058417174293886\n",
      "Predictor 8: Initial Spearman rho = -0.02647327497690244\n",
      "Predictor 9: Initial Spearman rho = 0.06138514077883111\n",
      "Predictor 10: Initial Spearman rho = 0.19659013489011004\n",
      "Predictor 11: Initial Spearman rho = 0.16446437685990753\n",
      "Predictor 12: Initial Spearman rho = 0.00980613914701243\n",
      "Predictor 13: Initial Spearman rho = 0.02513273254607998\n",
      "Predictor 14: Initial Spearman rho = -0.08815398023124783\n",
      "Predictor 15: Initial Spearman rho = -0.02578612507951387\n",
      "Predictor 16: Initial Spearman rho = 0.10035539189175557\n",
      "Predictor 17: Initial Spearman rho = 0.13134015102028995\n",
      "Predictor 18: Initial Spearman rho = 0.011201443523805815\n",
      "Predictor 19: Initial Spearman rho = 0.01342267807202367\n",
      "Predictor 20: Initial Spearman rho = -0.05756605767009179\n",
      "Predictor 21: Initial Spearman rho = -0.04206092532388616\n",
      "Predictor 22: Initial Spearman rho = 0.042769079803290984\n",
      "Predictor 23: Initial Spearman rho = 0.10734016557580031\n",
      "Predictor 24: Initial Spearman rho = -0.09686413029519837\n",
      "Predictor 25: Initial Spearman rho = 0.016328812026699783\n",
      "Predictor 26: Initial Spearman rho = -0.07671323450518551\n",
      "Predictor 27: Initial Spearman rho = 0.04112997224238048\n",
      "Predictor 28: Initial Spearman rho = 0.06967069822059613\n",
      "Predictor 29: Initial Spearman rho = -0.09817016519842273\n",
      "Predictor 30: Initial Spearman rho = 0.038421131325928365\n",
      "Predictor 31: Initial Spearman rho = 0.02844995617735973\n",
      "Predictor 32: Initial Spearman rho = -0.015310839962555363\n",
      "Predictor 33: Initial Spearman rho = -0.12942573340223795\n",
      "Predictor 34: Initial Spearman rho = 0.08747583229758052\n",
      "Predictor 35: Initial Spearman rho = -0.12033825102563847\n",
      "Predictor 36: Initial Spearman rho = -0.14757444242791662\n",
      "Predictor 37: Initial Spearman rho = -0.0072608339048296595\n",
      "Predictor 38: Initial Spearman rho = 0.052487449804021244\n",
      "Predictor 39: Initial Spearman rho = 0.06786430416719909\n",
      "Predictor 40: Initial Spearman rho = 0.008953203084424216\n",
      "Predictor 41: Initial Spearman rho = 0.20295527340467553\n",
      "Predictor 42: Initial Spearman rho = 0.14412518999539192\n",
      "Predictor 43: Initial Spearman rho = 0.07872592356052781\n",
      "Predictor 44: Initial Spearman rho = -0.15590200903371415\n",
      "Predictor 45: Initial Spearman rho = -0.04690773262413458\n",
      "Predictor 46: Initial Spearman rho = 0.044571723038470824\n",
      "Predictor 47: Initial Spearman rho = -0.015225321307203511\n",
      "Predictor 48: Initial Spearman rho = -0.1089507669182602\n",
      "\n",
      "Initial weights set to predictor 41 with weight 1. Initial Spearman rho = 0.20295527340467553\n",
      "\n",
      "Starting repeat 1/10...\n",
      "Repeat 1 best rho: 0.3122578670717079\n",
      "Updated best overall rho to 0.3122578670717079\n",
      "\n",
      "Starting repeat 2/10...\n",
      "Repeat 2 best rho: 0.34478646297843624\n",
      "Updated best overall rho to 0.34478646297843624\n",
      "\n",
      "Starting repeat 3/10...\n"
     ]
    }
   ],
   "source": [
    "# Run the simulation multiple times\n",
    "for _ in range(num_simulations):\n",
    "    # Load your data (ensure these paths are correct)\n",
    "    df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_ad.csv')\n",
    "    df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/advertisement/emb/static_embedding.csv')\n",
    "    \n",
    "    # Run the bayesian optimization function (make sure it's defined in this notebook or imported)\n",
    "    best_weights, best_rho = optimization.bayesian_optimization_fit(df1, df2, predictor_columns, task_name=task_name, cross_validate=False)\n",
    "    all_weights.append(best_weights)\n",
    "    spearman_rhos.append(best_rho)\n",
    "\n",
    "# Find the best (highest) Spearman rho and corresponding weights\n",
    "best_rho_index = np.argmax(spearman_rhos)\n",
    "best_rho = spearman_rhos[best_rho_index]\n",
    "best_weights = all_weights[best_rho_index]\n",
    "\n",
    "# Calculate predictions for each image using the best weights\n",
    "# Assuming `df2` contains predictor columns and `df1` contains the actual values\n",
    "df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_ad.csv')\n",
    "df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/advertisement/emb/static_embedding.csv')\n",
    "\n",
    "# Ensure that df1 and df2 are aligned by merging on 'image' column if necessary\n",
    "if 'image' in df1.columns and 'image' in df2.columns:\n",
    "    combined_df = pd.merge(df1, df2, on='image')\n",
    "    y_true = combined_df['Normalized Average'].values\n",
    "    X = combined_df[predictor_columns].values\n",
    "else:\n",
    "    y_true = df1['Normalized Average'].values\n",
    "    X = df2[predictor_columns].values\n",
    "\n",
    "# Get predicted values by multiplying X by best weights\n",
    "y_pred = X @ best_weights\n",
    "\n",
    "# Calculate the line of best fit for predicted vs. actual\n",
    "slope, intercept, _, _, _ = linregress(y_pred, y_true)  # Predicted (x) vs. Actual (y)\n",
    "line_x = np.linspace(y_pred.min(), y_pred.max(), 100)  # Restrict line_x to the range of predicted values\n",
    "line_y = slope * line_x + intercept  # Compute corresponding y values using the regression equation\n",
    "\n",
    "# Plot the scatter plot and line of best fit\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, y_true, label=\"Predicted vs. Actual\")  # Predicted on x, Actual on y\n",
    "plt.plot(line_x, line_y, color=\"red\", label=\"Line of Best Fit\")  # Best-fit line for predicted vs. actual\n",
    "plt.xlabel(\"CLIP-CBA Complexity Score (Predicted)\")\n",
    "plt.ylabel(\"Normalized Participant Complexity Rating (Actual)\")\n",
    "plt.title(f\"CLIP-CBA Optimization vs. Participant Ratings: Spearman Rho = {best_rho:.4f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation multiple times\n",
    "for _ in range(num_simulations):\n",
    "    # Load your data (ensure these paths are correct)\n",
    "    df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_art.csv')\n",
    "    df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/art/emb/static_embedding.csv')\n",
    "    \n",
    "    # Run the bayesian optimization function (make sure it's defined in this notebook or imported)\n",
    "    best_weights, best_rho = optimization.bayesian_optimization_fit(df1, df2, predictor_columns, task_name=task_name, cross_validate=True)\n",
    "    all_weights.append(best_weights)\n",
    "    spearman_rhos.append(best_rho)\n",
    "\n",
    "# Find the best (highest) Spearman rho and corresponding weights\n",
    "best_rho_index = np.argmax(spearman_rhos)\n",
    "best_rho = spearman_rhos[best_rho_index]\n",
    "best_weights = all_weights[best_rho_index]\n",
    "\n",
    "# Calculate predictions for each image using the best weights\n",
    "# Assuming `df2` contains predictor columns and `df1` contains the actual values\n",
    "df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_art.csv')\n",
    "df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/art/emb/static_embedding.csv')\n",
    "\n",
    "# Ensure that df1 and df2 are aligned by merging on 'image' column if necessary\n",
    "if 'image' in df1.columns and 'image' in df2.columns:\n",
    "    combined_df = pd.merge(df1, df2, on='image')\n",
    "    y_true = combined_df['Normalized Average'].values\n",
    "    X = combined_df[predictor_columns].values\n",
    "else:\n",
    "    y_true = df1['Normalized Average'].values\n",
    "    X = df2[predictor_columns].values\n",
    "\n",
    "# Get predicted values by multiplying X by best weights\n",
    "y_pred = X @ best_weights\n",
    "\n",
    "# Calculate the line of best fit for predicted vs. actual\n",
    "slope, intercept, _, _, _ = linregress(y_pred, y_true)  # Predicted (x) vs. Actual (y)\n",
    "line_x = np.linspace(y_pred.min(), y_pred.max(), 100)  # Restrict line_x to the range of predicted values\n",
    "line_y = slope * line_x + intercept  # Compute corresponding y values using the regression equation\n",
    "\n",
    "# Plot the scatter plot and line of best fit\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, y_true, label=\"Predicted vs. Actual\")  # Predicted on x, Actual on y\n",
    "plt.plot(line_x, line_y, color=\"red\", label=\"Line of Best Fit\")  # Best-fit line for predicted vs. actual\n",
    "plt.xlabel(\"CLIP-CBA Complexity Score (Predicted)\")\n",
    "plt.ylabel(\"Normalized Participant Complexity Rating (Actual)\")\n",
    "plt.title(f\"CLIP-CBA Optimization vs. Participant Ratings: Spearman Rho = {best_rho:.4f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation multiple times\n",
    "for _ in range(num_simulations):\n",
    "    # Load your data (ensure these paths are correct)\n",
    "    df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_interior_design.csv')\n",
    "    df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/interior_design/emb/static_embedding.csv')\n",
    "    \n",
    "    # Run the bayesian optimization function (make sure it's defined in this notebook or imported)\n",
    "    best_weights, best_rho = optimization.bayesian_optimization_fit(df1, df2, predictor_columns, task_name=task_name, cross_validate=False)\n",
    "    all_weights.append(best_weights)\n",
    "    spearman_rhos.append(best_rho)\n",
    "\n",
    "# Find the best (highest) Spearman rho and corresponding weights\n",
    "best_rho_index = np.argmax(spearman_rhos)\n",
    "best_rho = spearman_rhos[best_rho_index]\n",
    "best_weights = all_weights[best_rho_index]\n",
    "\n",
    "# Calculate predictions for each image using the best weights\n",
    "# Assuming `df2` contains predictor columns and `df1` contains the actual values\n",
    "df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_interior_design.csv')\n",
    "df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/interior_design/emb/static_embedding.csv')\n",
    "\n",
    "# Ensure that df1 and df2 are aligned by merging on 'image' column if necessary\n",
    "if 'image' in df1.columns and 'image' in df2.columns:\n",
    "    combined_df = pd.merge(df1, df2, on='image')\n",
    "    y_true = combined_df['Normalized Average'].values\n",
    "    X = combined_df[predictor_columns].values\n",
    "else:\n",
    "    y_true = df1['Normalized Average'].values\n",
    "    X = df2[predictor_columns].values\n",
    "\n",
    "# Get predicted values by multiplying X by best weights\n",
    "y_pred = X @ best_weights\n",
    "\n",
    "# Calculate the line of best fit for predicted vs. actual\n",
    "slope, intercept, _, _, _ = linregress(y_pred, y_true)  # Predicted (x) vs. Actual (y)\n",
    "line_x = np.linspace(y_pred.min(), y_pred.max(), 100)  # Restrict line_x to the range of predicted values\n",
    "line_y = slope * line_x + intercept  # Compute corresponding y values using the regression equation\n",
    "\n",
    "# Plot the scatter plot and line of best fit\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, y_true, label=\"Predicted vs. Actual\")  # Predicted on x, Actual on y\n",
    "plt.plot(line_x, line_y, color=\"red\", label=\"Line of Best Fit\")  # Best-fit line for predicted vs. actual\n",
    "plt.xlabel(\"CLIP-CBA Complexity Score (Predicted)\")\n",
    "plt.ylabel(\"Normalized Participant Complexity Rating (Actual)\")\n",
    "plt.title(f\"CLIP-CBA Optimization vs. Participant Ratings: Spearman Rho = {best_rho:.4f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation multiple times\n",
    "for _ in range(num_simulations):\n",
    "    # Load your data (ensure these paths are correct)\n",
    "    df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_objects.csv')\n",
    "    df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/objects/emb/static_embedding.csv')\n",
    "    \n",
    "    # Run the bayesian optimization function (make sure it's defined in this notebook or imported)\n",
    "    best_weights, best_rho = optimization.bayesian_optimization_fit(df1, df2, predictor_columns, task_name=task_name, cross_validate=False)\n",
    "    all_weights.append(best_weights)\n",
    "    spearman_rhos.append(best_rho)\n",
    "\n",
    "# Find the best (highest) Spearman rho and corresponding weights\n",
    "best_rho_index = np.argmax(spearman_rhos)\n",
    "best_rho = spearman_rhos[best_rho_index]\n",
    "best_weights = all_weights[best_rho_index]\n",
    "\n",
    "# Calculate predictions for each image using the best weights\n",
    "# Assuming `df2` contains predictor columns and `df1` contains the actual values\n",
    "df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_objects.csv')\n",
    "df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/objects/emb/static_embedding.csv')\n",
    "\n",
    "# Ensure that df1 and df2 are aligned by merging on 'image' column if necessary\n",
    "if 'image' in df1.columns and 'image' in df2.columns:\n",
    "    combined_df = pd.merge(df1, df2, on='image')\n",
    "    y_true = combined_df['Normalized Average'].values\n",
    "    X = combined_df[predictor_columns].values\n",
    "else:\n",
    "    y_true = df1['Normalized Average'].values\n",
    "    X = df2[predictor_columns].values\n",
    "\n",
    "# Get predicted values by multiplying X by best weights\n",
    "y_pred = X @ best_weights\n",
    "\n",
    "# Calculate the line of best fit for predicted vs. actual\n",
    "slope, intercept, _, _, _ = linregress(y_pred, y_true)  # Predicted (x) vs. Actual (y)\n",
    "line_x = np.linspace(y_pred.min(), y_pred.max(), 100)  # Restrict line_x to the range of predicted values\n",
    "line_y = slope * line_x + intercept  # Compute corresponding y values using the regression equation\n",
    "\n",
    "# Plot the scatter plot and line of best fit\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, y_true, label=\"Predicted vs. Actual\")  # Predicted on x, Actual on y\n",
    "plt.plot(line_x, line_y, color=\"red\", label=\"Line of Best Fit\")  # Best-fit line for predicted vs. actual\n",
    "plt.xlabel(\"CLIP-CBA Complexity Score (Predicted)\")\n",
    "plt.ylabel(\"Normalized Participant Complexity Rating (Actual)\")\n",
    "plt.title(f\"CLIP-CBA Optimization vs. Participant Ratings: Spearman Rho = {best_rho:.4f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation multiple times\n",
    "for _ in range(num_simulations):\n",
    "    # Load your data (ensure these paths are correct)\n",
    "    df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_scenes.csv')\n",
    "    df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/scenes/emb/static_embedding.csv')\n",
    "    \n",
    "    # Run the bayesian optimization function (make sure it's defined in this notebook or imported)\n",
    "    best_weights, best_rho = optimization.bayesian_optimization_fit(df1, df2, predictor_columns, task_name=task_name, cross_validate=True)\n",
    "    all_weights.append(best_weights)\n",
    "    spearman_rhos.append(best_rho)\n",
    "\n",
    "# Find the best (highest) Spearman rho and corresponding weights\n",
    "best_rho_index = np.argmax(spearman_rhos)\n",
    "best_rho = spearman_rhos[best_rho_index]\n",
    "best_weights = all_weights[best_rho_index]\n",
    "\n",
    "# Calculate predictions for each image using the best weights\n",
    "# Assuming `df2` contains predictor columns and `df1` contains the actual values\n",
    "df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_scenes.csv')\n",
    "df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/scenes/emb/static_embedding.csv')\n",
    "\n",
    "# Ensure that df1 and df2 are aligned by merging on 'image' column if necessary\n",
    "if 'image' in df1.columns and 'image' in df2.columns:\n",
    "    combined_df = pd.merge(df1, df2, on='image')\n",
    "    y_true = combined_df['Normalized Average'].values\n",
    "    X = combined_df[predictor_columns].values\n",
    "else:\n",
    "    y_true = df1['Normalized Average'].values\n",
    "    X = df2[predictor_columns].values\n",
    "\n",
    "# Get predicted values by multiplying X by best weights\n",
    "y_pred = X @ best_weights\n",
    "\n",
    "# Calculate the line of best fit for predicted vs. actual\n",
    "slope, intercept, _, _, _ = linregress(y_pred, y_true)  # Predicted (x) vs. Actual (y)\n",
    "line_x = np.linspace(y_pred.min(), y_pred.max(), 100)  # Restrict line_x to the range of predicted values\n",
    "line_y = slope * line_x + intercept  # Compute corresponding y values using the regression equation\n",
    "\n",
    "# Plot the scatter plot and line of best fit\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, y_true, label=\"Predicted vs. Actual\")  # Predicted on x, Actual on y\n",
    "plt.plot(line_x, line_y, color=\"red\", label=\"Line of Best Fit\")  # Best-fit line for predicted vs. actual\n",
    "plt.xlabel(\"CLIP-CBA Complexity Score (Predicted)\")\n",
    "plt.ylabel(\"Normalized Participant Complexity Rating (Actual)\")\n",
    "plt.title(f\"CLIP-CBA Optimization vs. Participant Ratings: Spearman Rho = {best_rho:.4f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation multiple times\n",
    "for _ in range(num_simulations):\n",
    "    # Load your data (ensure these paths are correct)\n",
    "    df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_sup.csv')\n",
    "    df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/suprematism/emb/static_embedding.csv')\n",
    "    \n",
    "    # Run the bayesian optimization function (make sure it's defined in this notebook or imported)\n",
    "    best_weights, best_rho = optimization.bayesian_optimization_fit(df1, df2, predictor_columns, task_name=task_name, cross_validate=False)\n",
    "    all_weights.append(best_weights)\n",
    "    spearman_rhos.append(best_rho)\n",
    "\n",
    "# Find the best (highest) Spearman rho and corresponding weights\n",
    "best_rho_index = np.argmax(spearman_rhos)\n",
    "best_rho = spearman_rhos[best_rho_index]\n",
    "best_weights = all_weights[best_rho_index]\n",
    "\n",
    "# Calculate predictions for each image using the best weights\n",
    "# Assuming `df2` contains predictor columns and `df1` contains the actual values\n",
    "df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_sup.csv')\n",
    "df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/suprematism/emb/static_embedding.csv')\n",
    "\n",
    "# Ensure that df1 and df2 are aligned by merging on 'image' column if necessary\n",
    "if 'image' in df1.columns and 'image' in df2.columns:\n",
    "    combined_df = pd.merge(df1, df2, on='image')\n",
    "    y_true = combined_df['Normalized Average'].values\n",
    "    X = combined_df[predictor_columns].values\n",
    "else:\n",
    "    y_true = df1['Normalized Average'].values\n",
    "    X = df2[predictor_columns].values\n",
    "\n",
    "# Get predicted values by multiplying X by best weights\n",
    "y_pred = X @ best_weights\n",
    "\n",
    "# Calculate the line of best fit for predicted vs. actual\n",
    "slope, intercept, _, _, _ = linregress(y_pred, y_true)  # Predicted (x) vs. Actual (y)\n",
    "line_x = np.linspace(y_pred.min(), y_pred.max(), 100)  # Restrict line_x to the range of predicted values\n",
    "line_y = slope * line_x + intercept  # Compute corresponding y values using the regression equation\n",
    "\n",
    "# Plot the scatter plot and line of best fit\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, y_true, label=\"Predicted vs. Actual\")  # Predicted on x, Actual on y\n",
    "plt.plot(line_x, line_y, color=\"red\", label=\"Line of Best Fit\")  # Best-fit line for predicted vs. actual\n",
    "plt.xlabel(\"CLIP-CBA Complexity Score (Predicted)\")\n",
    "plt.ylabel(\"Normalized Participant Complexity Rating (Actual)\")\n",
    "plt.title(f\"CLIP-CBA Optimization vs. Participant Ratings: Spearman Rho = {best_rho:.4f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation multiple times\n",
    "for _ in range(num_simulations):\n",
    "    # Load your data (ensure these paths are correct)\n",
    "    df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_vis.csv')\n",
    "    df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/visualizations/emb/static_embedding.csv')\n",
    "    \n",
    "    # Run the bayesian optimization function (make sure it's defined in this notebook or imported)\n",
    "    best_weights, best_rho = optimization.bayesian_optimization_fit(df1, df2, predictor_columns, task_name=task_name, cross_validate=False)\n",
    "    all_weights.append(best_weights)\n",
    "    spearman_rhos.append(best_rho)\n",
    "\n",
    "# Find the best (highest) Spearman rho and corresponding weights\n",
    "best_rho_index = np.argmax(spearman_rhos)\n",
    "best_rho = spearman_rhos[best_rho_index]\n",
    "best_weights = all_weights[best_rho_index]\n",
    "\n",
    "# Calculate predictions for each image using the best weights\n",
    "# Assuming `df2` contains predictor columns and `df1` contains the actual values\n",
    "df1 = pd.read_csv('/home/wallacelab/complexity-final/Savoias-Dataset/Ground truth/csv/global_ranking_vis.csv')\n",
    "df2 = pd.read_csv('/home/wallacelab/complexity-final/Embeddings/CLIP-HBA/Dora49/Savoias/visualizations/emb/static_embedding.csv')\n",
    "\n",
    "# Ensure that df1 and df2 are aligned by merging on 'image' column if necessary\n",
    "if 'image' in df1.columns and 'image' in df2.columns:\n",
    "    combined_df = pd.merge(df1, df2, on='image')\n",
    "    y_true = combined_df['Normalized Average'].values\n",
    "    X = combined_df[predictor_columns].values\n",
    "else:\n",
    "    y_true = df1['Normalized Average'].values\n",
    "    X = df2[predictor_columns].values\n",
    "\n",
    "# Get predicted values by multiplying X by best weights\n",
    "y_pred = X @ best_weights\n",
    "\n",
    "# Calculate the line of best fit for predicted vs. actual\n",
    "slope, intercept, _, _, _ = linregress(y_pred, y_true)  # Predicted (x) vs. Actual (y)\n",
    "line_x = np.linspace(y_pred.min(), y_pred.max(), 100)  # Restrict line_x to the range of predicted values\n",
    "line_y = slope * line_x + intercept  # Compute corresponding y values using the regression equation\n",
    "\n",
    "# Plot the scatter plot and line of best fit\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, y_true, label=\"Predicted vs. Actual\")  # Predicted on x, Actual on y\n",
    "plt.plot(line_x, line_y, color=\"red\", label=\"Line of Best Fit\")  # Best-fit line for predicted vs. actual\n",
    "plt.xlabel(\"CLIP-CBA Complexity Score (Predicted)\")\n",
    "plt.ylabel(\"Normalized Participant Complexity Rating (Actual)\")\n",
    "plt.title(f\"CLIP-CBA Optimization vs. Participant Ratings: Spearman Rho = {best_rho:.4f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "complexity_experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
